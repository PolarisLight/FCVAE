# 第一章 绪论

## 1.1 研究背景

### 1.1.1 图像增强的研究意义

人类传递信息的主要媒介是语言和图像。据统计，视觉信息占人类接收到的各种信息的80%，因此图像信息是一种非常重要的信息传播媒介和方式。图像传输系统包括图像采集、图像压缩、图像编码、图像存储、图像通信和图像显示。在实际应用中，每一部分都可能导致图像质量差，从而使图像传输的信息无法正常读取和识别。在图像采集过程中，由于光照环境或物体表面的反射，图像的整体照度不均匀，或者由于图像采集系统中的机械设备，采集噪声无法避免，或者图像显示设备的限制导致图像显示水平或颜色降低等。 

为了尽可能地获得理想的数字图像，需要图像增强技术来提高人们的视觉效果，如突出图像中物体的某些特征，从数字图像中提取物体的特征参数等，这些都有利于识别图像中物体。图像增强处理的主要内容是突出图像中感兴趣的部分，弱化或去除不必要的信息。这样，可以增强有用的信息，并且可以获得更实际的图像或者将其转换成更适合于人或机器分析和处理的图像。 

图像增强是对数字图像进行调整，使其结果更适合于显示或进一步的图像分析的过程。图像增强可以有目的地强调图像的整体或局部特性，将原来不清晰的图像变得清晰或强调某些感兴趣的特征，扩大图像中不同物体特征之间的差别，抑制不感兴趣的特征，使之改善图像质量、丰富信息量，加强图像判读和识别效果，满足某些特殊分析的需要。例如，可以移除噪波、锐化或亮化图像，以便更容易识别关键特征。 

### 1.1.2 低照度图像的限制条件

由于不可避免的环境和技术限制，许多照片通常是在非最佳照明条件下拍摄的。例如，在光照不足的夜间、阴天或光线阴暗的室内环境下，目标物体表面反射光所具有的能量发生衰减，传播到达人眼或相机等成像设备的通量减少，在亮度、对比度和饱和度等方面都会受到影响。由于照明度低而无法获取到物体真实的色彩信息和纹理细节，从而导致采集到的图像降质，这类颜色失真、信噪比和对比度都较低的退化图像，称为低照度图像。低照度图像通常有着较低的对比度和饱和度，图像整体灰度值较低且动态范围较小，细节信息严重丢失。【基于GAN的低照度图像】

由于低光子计数和低信噪比，在弱光下成像是十分具有挑战性的工作。在弱光条件下拍摄的图像存在对比度低、可见度低和ISO噪声高的问题，同时矛盾的是短曝光图像会产生噪声，而长曝光会导致图像模糊，这都是不符合需求的。这些问题既挑战了偏好高可见度图像的人类视觉感知，也挑战了许多依赖计算机视觉算法的智能系统，如全天自动驾驶和生物识别。【EnlightenGAN】人们提出了各种去噪、去模糊和增强技术，但它们在极端条件下的有效性受到限制，如夜间视频成像。

## 1.2 研究内容

低照度图像增强算法现如今主要有两个研究方向：传统图像增强方法及深度学习方法。传统图像增强方法主要是利用传统的数字图像处理方法，利用数学方法对数字图像进行时域或/和频域的增强，以提高低照度图像的可视性；而深度学习方法从16年前后开始崭露头角，逐渐成为目前研究的热门方向。深度学习方法利用新兴的神经网络算法，在待处理信息量不可扩充的前提下（即低照度图像本身就未包含场景中的所有细节信息），可以借助海量的同类数据或相似数据训练一个神经网络，然后让神经网络获得对图像内容进行理解、判断和预测的功能，这时候，再把待处理的低照度图像输入，神经网络就会自动为其进行增强处理。目前主流的数据集（如MEF、DICM和LIME等）的最佳方法全部由深度学习方法所占据。

本论文主要结合目前国内外经典或效果良好的研究成果，自主复现其算法的实现过程。对于传统的图像增强方法，尝试对其进行数学公式上的参数调整及优化，以求获得更好的效果；对于深度学习方法，分析其网络结构和损失函数，并尝试探索出一种新的图像处理方法。

# 第二章 国内外研究方向

## 2.1 传统低照度图像增强算法

### 2.1.1 基于暗通道先验去雾算法的低照度图像增强算法

暗通道先验去雾算法是图像处理专家何凯明在2009年提出的算法。暗通道先验是基于如下观察，在户外的无雾图像中，在大部分非天空区域，至少有一个通道值是很小一个数或趋近于零。利用该先验知识，结合带雾图像模型，可以直接估计雾霾的厚度，恢复出高质量的无雾霾图像。结果表明，该方法十分的有效。此外，作为除雾的副产品，还可以获得高质量的深度图。

在计算机视觉领域，一个常用的带雾图像表达式为：
$$
I(x) = J(x)t(x)+A(1-t(x))
$$
其中I为带雾图像，J为无雾图像，A为全球大气光成分，t为透射率。

基于这一理论模型，以及暗通道先先验，假设全球大气光值已知，便可计算出透射率。至于全球大气光值， 作者在文中给出的方法是，在暗通道中找出前0.1%最亮的点，即透射率最小的点。对于这些点，在带雾图中找到对于的点，并取它们中的所有通道最大的值作为A的近似。至此，带雾图I、全球大气光值A和透射率t都已知，就能计算出无雾图像J。

<img src="E:\Desktop\毕设\毕业论文初稿.assets\1612187692135.png" alt="1612187692135" style="zoom:50%;" />

在2010年，何凯明又提出了图像处理领域的重要滤波器：引导滤波器，其形式如下：
$$
W_{ij}(I)=\frac{1}{|\omega^2|}\sum_{k:(i,j)\in\omega_k}\left(1+\frac{(I_i-\mu_k)(I_j-\mu_k)}{\sigma_k^2+\epsilon}\right)
$$
其中$\mu_k$是窗口内像素点的均值，$I_i$和$I_j$指相邻两个像素点的值，$σ_k$代表窗口内像素点的方差，$\epsilon$是一个惩罚值。 

以原始图像的灰度图像作为引导图像，利用引导滤波器可以得到很好的透光率图像，从而得到高质量的去雾图像。

带雾图像的特征是图片泛白，即图像的像素值普遍偏高，这是暗通道先验告诉我们的。而低照度图像的特点是图像像素值普遍偏低。基于这种对应关系，可以将低照度图像进行反色处理（即$I_{out} = 255 - I_{in}$),然后使用暗通道去雾算法进行处理，再将其处理结果反色，即可得到精细的、高质量的照度增强图像。这种算法已经被Matlab收录作为其官方库函数imlocalbrighten。

### 2.1.2 基于融合的低照度图像增强算法

这篇文章来自于2016年的Signal Processing第129期。文章中提出了一种简单有效的基于融合的弱光照图像增强方法。首先，采用一种基于形态学逼近的光照估计算法，将观察到的图像分解为反射图像和照度图像。然后使用sigmoid函数和自适应直方图均衡化导出表示亮度改进和对比度增强版本的第一个分解照明的两个输入。基于这些输入设计两个权值，将导出的输入与相应的权值进行多尺度融合，从而产生可调整的照明方法。通过在适当的加权和融合策略下，融合了不同技术的优点来产生可调整的光照。最终的增强图像是通过将调整后的照度补偿回反射率得到的。通过这种合成，增强后的图像在细节增强、局部对比度改善和保持图像的自然感觉之间进行了权衡。该融合框架可以增强背景光、非均匀光照和夜间等弱光照条件下的图像。

<img src="E:\Desktop\毕设\毕业论文初稿.assets\1612187558687.png" alt="1612187558687" style="zoom:50%;" />

该算法首先获取到待增强图像RGB三个通道中每个像素的最大值，然后对其进行闭运算和由原图HSV空间的V通道（即明度通道）进行引导滤波，得到的图像被其称为“照度预测图”，用来表征环境光的强度；根据Retinex理论（该词由视网膜retina和皮层cortex合成而来），用原图除以该照度预测图，就能得到每个颜色的反射率图像；然后对照度预测图使用不同的计算方法来得到三张照度期望图，再根据函数关系算出它们分别的权重；在将照度期望图进行加权时，为了保证细节留存度，取权重的高斯金字塔和照度期望图的拉普拉斯金字塔对应相乘，然后经过上采样重建理想的照度图；最后，将该理想照度图与三个通道的反射率相乘，即可得到增强后的图像。

## 2.2 基于深度学习的低照度图像增强算法

### 2.2.1 基于RAW格式的低照度图像增强网络

这是2018年发表在CVPR上的一篇文章，其最大的特点和贡献是自己捕获了一个RAW格式（即直接从摄像机的感光元件引出，未经处理和编码的图像格式）短曝光微光图像数据集，以及相应的长曝光参考图像。利用现有的数据集，作者开发了一个基于完全进化网络的端到端训练的微光图像处理流水线。该网络直接对原始传感器数据进行操作，并取代了许多传统的图像处理管道，而传统的图像处理管道往往对此类数据的处理效果较差。

<img src="E:\Desktop\毕设\毕业论文初稿.assets\1612189013370.png" alt="1612189013370" style="zoom:50%;" />

网络结构如图所示，先将RAW格式的图像解码为RGBG的四通道图像矩阵，然后经过卷积神经网络（作者使用的是U-Net），得到12个颜色通道、大小为原图的一半的图像，再经过亚像素层复原到全分辨率大小，且输出为RGB三通道。在他们的模型中，还引入了期望的放大因子。这是由相机的感光度决定的一个参数。网络使用L1范数进行训练。由于低曝光图像往往带有噪声， 而作者用于训练的数据集是自己获取的，因此该网络还具有一定的去噪能力。

由于作者完全开源了这一数据集，我成功复现了这一论文的结果。该网络能从几乎全黑的RAW格式图像中增强出能分辨大部分场景的图像，这一结果确实十分令人惊艳。但是在我的复现中，我也发现了该方法的诸多限制：首先，该网络要求输入RAW格式的图像，而不同的相机厂商的RAW图片格式也是不一致的；其次，期望放大因子并不是计算得出的参数，而是完全由相机感光度决定的参数。这两项特征决定了该方法必须针对不同的相机训练不同的网络，以至于在实际应用中几乎没有泛化能力。另外，该网络的执行时间较慢，难以进行实时图像增强。

### 2.2.2 基于对抗生成网络的EnlightenGAN

深度学习图像处理通常需要大量的输入图-目标图数据对，用于训练网络参数。但在现实生活中，想要获取到大量完全相同场景下的低照度-正常照度图像是十分困难的。而在若干网络模型中，就有一种不依赖于数据集就可以进行训练的模型：对抗生成网络（GAN）。发表在IEEE Transaction on Image Processing, 2020 的这篇论文就提出了一种高效的无监督对抗生成网络，称为EnlightenGAN。它可以在没有低照度-正常照度图像对的情况下进行训练，并且在各种真实的测试图像上有很好的推广性。作者提出用从输入本身提取的信息来正则化非配对训练，而不是用地面真值数据来监督学习，并针对微光图像增强问题进行了一系列创新，包括全局-局部鉴别器结构、自正则化感知丢失融合和注意机制。

网络同样采用U-Net结构，将输入图像的光照通道$I$归一化后使用$1-I$作为自正则注意力图。然后，调整注意力图的大小并将所其与所有中间特征图以及输出图像相乘。作者强调，注意力图是一种自我规范的形式，而非监督学习；并且该方法能有效改善视觉质量。注意力引导的U-Net生成器是由8个卷积块实现的。每个块由两个3*3个卷积层组成，然后是LeakyReLu和一个批量规范化层。在上采样阶段，作者将标准反卷积层替换为一个双线性上采样层和一个卷积层，以减轻棋盘伪影。EnlightenGAN的最终的结构如【2】所示。

<img src="E:\Desktop\毕设\毕业论文初稿.assets\1612195399060.png" alt="1612195399060" style="zoom:50%;" />

该文章有不少值得借鉴的地方，比如关于无监督学习、更轻量级的GAN、全局-局部判决器的应用、图像质量评价标准的应用等。在一般的背光图像处理上，该网络也具有不错的增强效果，但对于更为极端的低照度环境，该对抗生产网络就难以发挥其效果。

### 2.2.3 基于零参考深度曲线估计的微光图像增强算法

于2020年3月发表在CVPR上的这种算法，在八个主要的低照度图像增强数据集上占据了五个的最佳方法。这种算法并非像其他算法一样通过上采样或者反卷积直接得到输出图片，而是将该任务转化为一个特定于图像的曲线估计问题（图像作为输入，曲线作为输出），利用估算出的参数对原图像进行像素级的曲线运算，从而获得增强图像。 另外，这种网络的训练也具有不依赖成对数据集的特点，故称为零参考（Zero-reference）。

<img src="E:\Desktop\毕设\毕业论文初稿.assets\1612264663391.png" alt="1612264663391" style="zoom:50%;" />

受到图像编辑软件中"曲线调整"功能的启发，作者尝试设计一类能够将低照度图像自动映射到增强图像的曲线，曲线参数是自适应的，并仅取决于输入图像。设计这样的曲线有三个要求：

1.增强图像的像素值应归一化；

2.设计的曲线应该是单调的，从而保证相邻像素的差异；

3.曲线应该尽可能简单，以至于在反向传播时是可导的。

为了达到上述的要求，作者设计了一个二次曲线：
$$
LE(I(x);\alpha)=I(x)+\alpha I(x)(1-I(x))
$$
其中，x为像素坐标，$LE(I(x); α)$为输入图像I(x)的增强结果，$α\in[-1,1]$为可训练的曲线参数(修改曲线的大小并控制曝光度)。每个像素都归一化为[0,1]，并且所有操作都是像素级的。使用时，在输入的RGB通道分别应用LE曲线，这可以更好地保持固有颜色以及避免过拟合。

通过迭代上式，可以使得调整变得更灵活，从而使得模型能够适应于各种弱光条件下 ：
$$
LE_n(I(x);\alpha)=LE_{n-1}(x)+\alpha_nLE_{n-1}(x)(1-LE_{n-1}(x))
$$
其中，n为迭代的次数(控制曲率，文章中将n设置为8，这可满足大多数情况)，当n为1时，式(4)就退化为了(3)。

为了学习到输入图像与上述参数图之间的映射关系，作者使用了Deep Curve Estimation Network (DCE-Net)，输入为低照度图像，输出为一组用于高阶曲线的像素级曲线参数图。整个网络的参数量为79416，十分轻量。

为了避免选择数据集的限制，这种算法同样另辟蹊径，用损失函数来摆脱对成对数据集的依赖。该网络的损失函数由四个部分组成：空间一致性损失、颜色恒常性损失、曝光控制度损失和平滑度损失。其中，后三种损失都是仅需要输出图像本身就能计算，而第一种损失则是仅需要输入和输出图像就能计算。这是由于网络本身输出的仅是参数map，最终的增强图像是在低照度图像的基础上通过二次曲线迭代计算而来，故增强图像本身必然携带有原图像的色彩和边缘等信息，而不像传统神经网络一样必须从零开始进行学习。

该算法在八个主要的低照度图像增强数据集上占据了五个的最佳方法，其效果毋庸置疑。通过在原图的基础上使用神经网络得到的参数图进行曲线迭代运算以获得增强图像，摆脱了对成对数据集的依赖。其设计的损失函数涵盖了颜色、连续性、亮度三个方面，能较好地优化网络，十分具有启发性。

# 第三章 本人的工作及成果

## 3.1 对传统低照度图像增强算法进行调参优化

2.1.2中基于融合的低照度图像增强算法是我调研和优化的重要部分。我将对该算法进行详细介绍并且尝试对其中的过程和参数进行调整，以获得更好的效果。

首先，根据Retinex理论，我们原有的图像是由环境亮度乘以每个颜色通道的反射率得到的，即
$$
S^c(x,y)=R^c(x,y)I(x,y)
$$
其中S为测量图，R为反射率图，I为照度图（环境亮度），c为颜色通道。由于照度图是环境亮度决定的，而反射率图是由物体本身的特质决定的，因此基于这个理论，我们可以将环境亮度和每个通道的反射率（即颜色信息）分开，从而起到增加环境亮度的效果。

![img](E:\Desktop\毕设\毕业论文初稿.assets\image16124214418910.png)

为了得到照度图，首先取三个通道中的最大值，即
$$
L(x,y)=max_{c\in(R,G,B)}S^c(x,y)
$$
这一步相当于将图片反色并取暗通道，故称其为取图片的“亮通道”。

![img](E:\Desktop\毕设\毕业论文初稿.assets\image16124214622460.png)

然后，为平滑亮通道中的边缘和噪声，以获得更加接近于环境光照射的效果，对其进行形态学运算中的闭操作，并规范化。
$$
I=\frac{L\cdot P}{255}
$$
其中·代表形态学的闭操作。根据经验选择盘形核作为算子。经实测，算子大小对结果的影响并不大。

![img](E:\Desktop\毕设\毕业论文初稿.assets\image16124214711940.png)

闭运算后的照度图已经较为有效，但作者选择用引导滤波对其进行进一步优化。由测量图进行RGB到HSV空间变换后的V空间即明度空间引导的引导滤波可更好的保留照度图的大型轮廓，其公式如下：
$$
I_i\leftarrow \sum_j W_{ij}(g)I_j,
$$
其中i和j是像素坐标，W是引导滤波的滤波核，即
$$
W_{ij}(g)=\frac{1}{|\omega^2|}\sum_{k:(i,j)\in\omega_k}\left(1+\frac{(g_i-\mu_k)(g_j-\mu_k)}{\sigma_k^2+\epsilon}\right)
$$
![img](E:\Desktop\毕设\毕业论文初稿.assets\image16124214810020.png)

上面的步骤可以看作是暗通道去雾算法在增强方面的表现形式。

作者将这一张照度图进行sigmoid变换
$$
I_2(x,y)=\frac{2}{\pi}arctan(\lambda I(x,y)),\\
其中:\lambda = 10+\frac{1-I_{mean}}{I_{mean}}
$$
在同一张图中，图像的均值一定，其函数图像如下图

<img src="E:\Desktop\毕设\毕业论文初稿.assets\1612356316745.png" alt="1612356316745" style="zoom:50%;" />

可以看出，这条曲线是将图像亮度进行非线性增强，并且不会超出范围。这样得到的图作为第二张照度图。

![img](E:\Desktop\毕设\毕业论文初稿.assets\image16124215190650.png)

第三张照度图是原照度图经过对比度限制的直方图均衡化（CLAHE）得到的，能在保证对比度的前提下提高图像的亮度。

![img](E:\Desktop\毕设\毕业论文初稿.assets\image16124215553020.png)

接下来，根据以下两个公式，分别以像素级计算出每张照度图的亮度信息权重图以及对比度信息权重图
$$
W_{B,k} \left(x,y\right)=\mathrm{exp}\left\lbrace -\frac{{\left(I_k \left(x,y\right)-0\ldotp 5\right)}^2 }{2{\left(0\ldotp 25\right)}^2 }\right\rbrace
$$

$$
W_{C,k}(x,y)=I_k(x,y)(1+cos(\alpha H(x,y)+\phi)S(x,y))
$$

其中，H(x,y)和S(x,y)分别为测量图的HSV颜色空间的H通道（色调）和S通道（饱和度）。

以对比度最大的$I_3$为例：

![img](E:\Desktop\毕设\毕业论文初稿.assets\image16124216407000.png)

![img](E:\Desktop\毕设\毕业论文初稿.assets\image16124216497540.png)

最终的权重等于以上两种权重的成绩归一化的结果
$$
W_k(x,y)=W_{B,k}(x,y)W_{C,k}(x,y)\\
\overline W_k(x,y)=\frac{W_k(x,y)}{\sum_kW_k(x,y)}
$$
![img](E:\Desktop\毕设\毕业论文初稿.assets\image16124216682860.png)

由于权重已被归一化，可以直接将权重与对应照度图相乘然后相加，即可得到结果。但是经实验，直接融合的增强图像会产生伪影结果。这主要是由于权重图的强变换所引起的。通常来说，为了克服这一问题，需采用多尺度线性滤波器或非线性滤波器。而非线性滤波器需要复杂的计算，因此作者选择采用多尺度金字塔技术。基于拉普拉斯算子，每个输入图像被表示为在不同尺度下计算的模式之和。输入被高斯核卷积，产生低通滤波版本。将每个输入照度图分解成一个拉普拉斯金字塔来提取图像特征，并将每个归一化的权重图分解成一个高斯金字塔来平滑强变换。再将拉普拉斯金字塔和高斯金字塔同阶对应相乘，然后经上采样还原成原图大小。
$$
\begin{array}{l}
F_l \left(x,y\right)=\sum_k G_l \left\lbrace \bar{W_k } \left(x,y\right)\right\rbrace L_l \left\lbrace I_k \left(x,y\right)\right\rbrace ,\\
I_{\mathrm{final}} \left(x,y\right)=\sum_l U_d \left(F_l \left(x,y\right)\right)
\end{array}
$$
经验证，这种方法可以有效保留细节，去除伪影。因为它融合的是图像的特征而不是强度。此外，拉普拉斯算子和高斯算子都是成熟的技术，在实际应用中易于实现。

最终还原的图像即是我们想要得到的理想照度图。将该理想照度图与三通道反射率图分别相乘，即可得到三通道的最终增强图像。

![img](E:\Desktop\毕设\毕业论文初稿.assets\image16124227089600.png)

由于该论文并未提供代码，复现这一论文花费了我较多的时间。这种算法的效果还是较为令人满意的，在处理一般的背光图片时，能将图片增强到适合人眼的光照强度，并且较好地保留图片的颜色和细节特征。但是，当面对较为极端的低照度场景时，由于在拆分照度图时CLAHE会限制其对比度，无法将图像增强至理想亮度。因此，我使用HE来代替，在较低照度的场景获得了更好的效果。

![QQ截图20210204154011](E:\Desktop\毕设\毕业论文初稿.assets\QQ截图20210204154011.jpg)

另外，根据其数学意义，我将亮度信息权重($W_B$)计算公式中的分子参数从0.5调整为1，使其单调递增，得到如下结果：

![1612426137822](E:\Desktop\毕设\毕业论文初稿.assets\1612426137822.png)

与作者的方法相比，增强效果有了一定的提升。

在研究与复现该论文时，我也发现了这种算法的诸多制约因素。在算法设计时未考虑噪声因素，导致在增强极低照度的带噪声图时，会将噪声一并增强。不仅如此，由于多尺度金字塔操作，噪声信息会被放大到大型区域，从而导致图像的色偏以及细节的撕裂。![无标题](E:\Desktop\毕设\毕业论文初稿.assets\无标题.png)

另外，金字塔操作十分耗时，以至于该算法难以做到实时性。

## 3.2 基于Retinex理论的低照度增强算法

在研究和验证了大量低照度图像增强算法后，我开始尝试探索一种全新的、完整的图像增强算法。我期望它具有以下的特征：

1.使用传统数字图像处理和深度学习结合的方法；

2.能够将低照度图像增强至肉眼能够舒适得分辨出图像内容的亮度；

3.在增强画面信息的同时能一定程度地去掉低照度图像中的噪声；

4.在去噪的同时能尽可能保留图像的细节；

5.处理速度尽可能快，尽可能达到一秒28帧的实时视频标准。

### 3.2.1 低照度增强流程

根据以上需求，我设计出这样一个完整的低照度图像增强流程：

#### 【图片还没画】

基于Retinex理论，我将归一化的低照度图分解为照度图和反射率图。将照度图做增强处理，反射率图做去噪处理，能得到理想照度图和理想反射率图。将这两张理想图像进行融合，就可得到最终的增强图像。

### 3.2.2 增强网络：FCVAE

#### ![捕获](E:\Desktop\毕设\毕业论文初稿.assets\捕获.PNG)

增强网络使用的是自主设计的网络结构，我称其为FCVAE，取自于我的两个灵感来源：FCN（全卷积神经网络）和VAE（变分自编码器）。该网络可以做到输入一张低照度图片，生成一张该图片的理想照度预测图（三通道）。该网络模型去掉了VAE的全连接层，仅采用卷积层，且编码器和解码器完全对称，故可以从一张原有图片生成另一张图片，并且理论上可以适应所有尺寸的图像输入。需要注意的是，全卷积的结构对图像输入的尺寸有下限要求。由于池化层的存在，网络会进行若干步的$1/2*1/2$尺寸缩小，若图像尺寸不为$（2*池化层数量）$的整数倍，则最终的输出尺寸会有一定的损失。因此，我将池化层的数量设计为2，以适合大多数的图像输入。并且该网络结构也因此变得极为轻量和高效。

在网络激活函数的选择上，所有的卷积层使用的是Tanh函数，以求能够捕获到尽可能多的图像特征；所有的反卷积层使用的是ReLu函数，以保证最终的输出在$[0,1]$之间。

在损失函数的选择上，我参考了DEC-Net的损失函数，使用了基频损失、色彩恒常性损失和空间一致性损失三个损失函数。

**基频损失** 基频代表这一张图像的能量分布，即主要的颜色和强度。我选择的是输入-目标图像对之间的二范数，即
$$
L_{base} = \sum||I_{target}-I_{input}||_2
$$
其中$I_{input}和I_{target}$分别是输入的低照度图像和目标的正常照度图像。

**色彩恒常性损失 ** 根据灰度世界颜色恒常性假设[2]，每个传感器通道中的颜色在整个图像上平均为灰色。因此我参考了DEC-Net的损失函数，设计了二元色彩恒常性损失，使不同通道的均值保持近似的关系，以校正增强图像中潜在的颜色偏差。色彩恒常性损失$L_{col}$可以表示为：
$$
L_{col} = \sum_{\forall (p,q)\in \varepsilon}|(J_{target}^p-J_{target}^q)^2-(J_{input}^p-J_{input}^q)^2|,\varepsilon=\{(R; G); (R; B); (G; B)\}
$$
其中，$J_{target}^p和J_{input}^p$分别表示目标图片和输入图片在p通道的平均强度,$(p,q)$表示一个颜色通道对。

**空间一致性损失** 该损失函数借鉴于DEC-Net。空间一致性通过保持输入图像与其增强版本之间相邻区域的差异来鼓励增强图像的空间一致性：
$$
L_{spa} = \frac{1}{K}\sum^K_{i=1}\sum_{j\in\Omega(i)}(|Y_i-Y_j|-|I_i-I_j|)^2
$$
其中K是区域数量，$\Omega(i)$是以$i$为中心的四个相邻区域（上下左右）.$Y和I$是目标图像和输入图像在局部区域的平均强度。

**总损失** 总损失表达如下：
$$
I_{total}=W_{base}L_{base}+W_{col}L_{col}+W_{spa}L_{spa},
$$
其中$W_{base}、W_{col}和W_{spa}$是三个损失对应的权重的权重。

另外，在训练时我手动给输入图像增加了$N(0,0.04)$的高斯噪声。经实测，网络不仅获得了一定的抗噪声能力，还能够更加有效地保留图像的细节。

### 3.2.3 去噪网络：ADNet

图像去噪网络使用了哈尔滨工业大学与北京大学的研究人员发表在2020年121期Neural Networks上的ADNet去噪网络。其网络结构如下：

![1612742301819](E:\Desktop\毕设\毕业论文初稿.assets\1612742301819.png)

该网络使用稀疏机制、特征增强机制和注意力机制，在仅有17层的小网络下提取显著性特征从而进行图像去噪的工作。网络主要有四个模块：一个稀疏块（SB），一个特征增强块（FEB）, 一个注意力机制（AB）和一个重构块(RB) 。SB利用空洞卷积和普通卷积来实现稀疏机制并能在效率和性能上达到平衡。FEB利用长路径集成全局和局部的特征信息来增强去噪模型的表达能力。AB是被用于提取隐藏在复杂背景中的噪声信息。该模块对于复杂的噪声图像（真实噪声图像和盲噪声）是非常有效的。同时，FEB和AB能共同提高训练噪声模型的效率和减少复杂度。

### 3.2.4 其他

对该流程中的传统算法部分，我也进行了一部分优化。其中，照度图取图像亮通道的这一过程，由于引导滤波在数学原理上的原因，容易造成反射率图像素值大于1的情况，形成溢出，不便于计算。因此我使用了均值滤波来代替引导滤波，其效果并不逊色。另外，经过神经网络计算的两张结果图可以看作是两张独立的图像，故可以进行线性融合。经测试，将这两张图像分别以50%的权重相加，可得到最好的增强效果。

### 3.2.5 训练和测试

**实施细节** 基于CNN的模型通常使用自捕获配对数据进行网络训练。我使用LOLDataset中的our485（485对）低照度-正常照度图像数据对进行训练，同时使用其eval15（15对）图像数据对进行测试。为测试其抗噪声性能，特地选择了一张$0.5 Lux$的极低照度噪声图进行测试。由于我使用的了全卷积神经网络结构，因此没有必要调整图像的大小。

我在Nvidia GeForce GTX1050(4GB)显卡上用Pytorch实现了我的框架。由于显存限制，batch size只能设置为2。利用$N(0,0.02)$来初始化卷积层和反卷积层的初始权重。我使用了Adam优化器，并采用线性learning rate decay策略修正学习率，每一个小时将学习率降为原来的一半，得到了良好的训练成果。设置$W_{base}$为$1/100$,$W_{spa}$为100，$W_{col}$为20。

**视觉效果比较**  由于基于RAW格式的网络无法用正常RGB图像作为输入，无法作为比较项，故本次视觉效果的对象为：本算法、imlocalbrighten、基于融合的传统增强算法、零参考深度曲线估计法和EnlightenGAN。

# 第四章 总结
